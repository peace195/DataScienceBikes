{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "from datetime import datetime\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "from os.path import exists\n",
    "from os import makedirs\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_dictionary = {'San Francisco': 94107,\n",
    "                 'Redwood City': 94063,\n",
    "                 'Palo Alto': 94301,\n",
    "                 'Mountain View': 94041,\n",
    "                 'San Jose': 95113}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of station is: 76\n",
      "Example for station 2: [37.329732, -121.901782, 27] 95113\n"
     ]
    }
   ],
   "source": [
    "\"\"\"read station_data.csv file\n",
    "\n",
    "returns\n",
    "    station_dictionary {id: [lat, long, dock count]}\n",
    "    station_zip_dictionary {id: zip}\n",
    "\"\"\"\n",
    "station_dictionary = defaultdict(list)\n",
    "station_zip_dictionary = {}\n",
    "with open('./bikes_data/data/station_data.csv', 'r') as station_data:\n",
    "  station_data.readline()\n",
    "  reader = csv.reader(station_data, delimiter=',', quotechar='|')\n",
    "  for row in reader:\n",
    "    for i in range(2, 5):\n",
    "      station_dictionary[int(row[0])].append(ast.literal_eval(row[i]))\n",
    "    station_zip_dictionary[int(row[0])] = zip_dictionary[row[5]]\n",
    "\n",
    "station_dictionary = collections.OrderedDict(sorted(station_dictionary.items()))\n",
    "print(\"Number of station is:\", len(station_dictionary))\n",
    "print(\"Example for station 2:\", station_dictionary[2], station_zip_dictionary[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example for (01/09/2014, 95113): [86, 72, 58, 60, 54, 50, 86, 59, 31, 29.86, 29.81, 29.75, 10, 10, 10, 17, 5, 22, 0, 0, 0, 296]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"read weather_data.csv file\n",
    "\n",
    "returns\n",
    "    weather_dictionary {(date, zip): [Max Temperature, Mean Temperature, ...]}\n",
    "\"\"\"\n",
    "events_dictionary = {'': 0, 'Rain': -1, 'Fog-Rain': -2, 'Rain-Thunderstorm': -3, 'Fog': -4}\n",
    "weather_dictionary = defaultdict(list)\n",
    "with open('./bikes_data/data/weather_data.csv', 'r') as weather_data:\n",
    "  weather_data.readline()\n",
    "  reader = csv.reader(weather_data, delimiter=',', quotechar='|')\n",
    "  for row in reader:\n",
    "    for i in range(1, 23):\n",
    "      if row[i] in events_dictionary:\n",
    "        weather_dictionary[(row[0], int(row[23]))].append(events_dictionary[row[i]])\n",
    "      else:\n",
    "        weather_dictionary[(row[0], int(row[23]))].append(ast.literal_eval(row[i]))\n",
    "\n",
    "print(\"Example for (01/09/2014, 95113):\", weather_dictionary[('01/09/2014', 95113)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of net rate dictionary: {('31/08/2015', 50, 23): 0, ('31/08/2015', 70, 23): 1, ('31/08/2015', 31, 23): 0, ('31/08/2015', 27, 23): 0, ('31/08/2015', 47, 23): 0, ('31/08/2015', 64, 23): 0, ('31/08/2015', 10, 23): 0, ('31/08/2015', 8, 23): 0, ('31/08/2015', 51, 23): -1, ('31/08/2015', 60, 23): 1, ('31/08/2015', 68, 23): 0, ('31/08/2015', 60, 22): 0, ('31/08/2015', 74, 22): 0, ('31/08/2015', 56, 22): 0, ('31/08/2015', 55, 22): 0, ('31/08/2015', 47, 21): 0, ('31/08/2015', 66, 22): 0, ('31/08/2015', 60, 21): 0, ('31/08/2015', 77, 22): 0, ('31/08/2015', 67, 21): 0}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"read trip_data.csv file\n",
    "\n",
    "returns\n",
    "    trip_started_dictionary {(date, station id, hour): count}\n",
    "    trip_ended_dictionary {(date, station id, hour): count}\n",
    "    net_rate_dictionary {(date, station id, hour): net rate}\n",
    "\"\"\"\n",
    "trip_started_dictionary = {}\n",
    "trip_ended_dictionary = {}\n",
    "net_rate_dictionary = {}\n",
    "date_list = []\n",
    "with open('./bikes_data/data/trip_data.csv', 'r') as trip_data:\n",
    "  trip_data.readline()\n",
    "  reader = csv.reader(trip_data, delimiter=',', quotechar='|')\n",
    "  for row in reader:\n",
    "    date_list.append(row[1].split(' ')[0])\n",
    "    if (row[1].split(' ')[0], int(row[2]), int(row[1].split(' ')[1].split(':')[0])) in trip_started_dictionary:\n",
    "      trip_started_dictionary[(row[1].split(' ')[0], int(row[2]), int(row[1].split(' ')[1].split(':')[0]))] += 1\n",
    "    else:\n",
    "      trip_started_dictionary[(row[1].split(' ')[0], int(row[2]), int(row[1].split(' ')[1].split(':')[0]))] = 0\n",
    "     \n",
    "    if (row[1].split(' ')[0], int(row[2]), int(row[1].split(' ')[1].split(':')[0])) not in trip_ended_dictionary:\n",
    "      trip_ended_dictionary[(row[1].split(' ')[0], int(row[2]), int(row[1].split(' ')[1].split(':')[0]))] = 0\n",
    "      \n",
    "    if (row[3].split(' ')[0], int(row[4]), int(row[3].split(' ')[1].split(':')[0])) in trip_ended_dictionary:\n",
    "      trip_ended_dictionary[(row[3].split(' ')[0], int(row[4]), int(row[3].split(' ')[1].split(':')[0]))] += 1\n",
    "    else:\n",
    "      trip_ended_dictionary[(row[3].split(' ')[0], int(row[4]), int(row[3].split(' ')[1].split(':')[0]))] = 0\n",
    "  \n",
    "    if (row[3].split(' ')[0], row[4], int(row[3].split(' ')[1].split(':')[0])) not in trip_started_dictionary:\n",
    "      trip_started_dictionary[(row[3].split(' ')[0], int(row[4]), int(row[3].split(' ')[1].split(':')[0]))] = 0\n",
    "      \n",
    "for key in trip_ended_dictionary:\n",
    "  net_rate_dictionary[key] = trip_ended_dictionary[key] - trip_started_dictionary[key]\n",
    "  \n",
    "print(\"Example of net rate dictionary:\", dict(list(net_rate_dictionary.items())[0:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of total data is: 3285\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Generate samples and labels\"\"\"\n",
    "dates = list(set([datetime.strptime(ts, \"%d/%m/%Y\") for ts in date_list]))\n",
    "dates.sort()\n",
    "sorteddates = [datetime.strftime(ts, \"%d/%m/%Y\") for ts in dates]\n",
    "\n",
    "samples = []\n",
    "labels = []\n",
    "\n",
    "for date in sorteddates:\n",
    "  for time in range(7, 16):\n",
    "    try:\n",
    "      data_tmp = []\n",
    "      for i in range(time, time + 3):\n",
    "        matrix_features = []\n",
    "        for station in station_dictionary.keys():\n",
    "          if (date, station, i) not in net_rate_dictionary:\n",
    "            trip_started_dictionary[(date, station, i)] = 0\n",
    "            trip_ended_dictionary[(date, station, i)] = 0\n",
    "            net_rate_dictionary[(date, station, i)] = 0\n",
    "            \n",
    "          matrix_features.append(station_dictionary[station] + \n",
    "                                [trip_started_dictionary[(date, station, i)]] +\n",
    "                                [trip_ended_dictionary[(date, station, i)]] +\n",
    "                                [net_rate_dictionary[(date, station, i)]] +\n",
    "                                weather_dictionary[(date, station_zip_dictionary[station])])\n",
    "        data_tmp.append(matrix_features)\n",
    "\n",
    "      label_tmp = []\n",
    "      for station in station_dictionary.keys():\n",
    "        label_tmp.append(net_rate_dictionary[(date, station, time + 2)])\n",
    "\n",
    "      labels.append(label_tmp)\n",
    "      samples.append(data_tmp)\n",
    "    except KeyError:\n",
    "      continue\n",
    "      \n",
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "print(\"Length of total data is:\", len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training RMSE: 1.9919546364071867 Validation RMSE: 2.1622747719718016\n",
      "Epoch: 1 Training RMSE: 1.9860143199781026 Validation RMSE: 2.1668802238857285\n",
      "Epoch: 2 Training RMSE: 1.9763405853036342 Validation RMSE: 2.165387879382698\n",
      "Epoch: 3 Training RMSE: 1.9833102604075086 Validation RMSE: 2.154878002721649\n",
      "Epoch: 4 Training RMSE: 1.977406944722332 Validation RMSE: 2.166464405572656\n",
      "Epoch: 5 Training RMSE: 1.976396023980252 Validation RMSE: 2.164469838811253\n",
      "Epoch: 6 Training RMSE: 1.977518844392532 Validation RMSE: 2.162302040990676\n",
      "Epoch: 7 Training RMSE: 1.9720294687922661 Validation RMSE: 2.1556344379956225\n",
      "Epoch: 8 Training RMSE: 1.9630022882165414 Validation RMSE: 2.147302142117514\n",
      "Epoch: 9 Training RMSE: 1.9022101902707287 Validation RMSE: 2.030685139457768\n",
      "Epoch: 10 Training RMSE: 1.7481934723180512 Validation RMSE: 1.866161580363842\n",
      "Epoch: 11 Training RMSE: 1.6248917139834724 Validation RMSE: 1.7897408888462303\n",
      "Epoch: 12 Training RMSE: 1.569810900986989 Validation RMSE: 1.778284600330973\n",
      "Epoch: 13 Training RMSE: 1.5289842177618251 Validation RMSE: 1.7416717954700507\n",
      "Epoch: 14 Training RMSE: 1.4915992386718184 Validation RMSE: 1.6926986009916685\n",
      "Epoch: 15 Training RMSE: 1.4504542891719667 Validation RMSE: 1.6542165938380173\n",
      "Epoch: 16 Training RMSE: 1.4176914382294004 Validation RMSE: 1.6345902336968352\n",
      "Epoch: 17 Training RMSE: 1.3955855845100553 Validation RMSE: 1.6151949492439168\n",
      "Epoch: 18 Training RMSE: 1.3781233252932732 Validation RMSE: 1.5977149822481544\n",
      "Epoch: 19 Training RMSE: 1.3642114095927707 Validation RMSE: 1.5871790945082032\n",
      "Epoch: 20 Training RMSE: 1.34971984806969 Validation RMSE: 1.5828092540228302\n",
      "Epoch: 21 Training RMSE: 1.341193000715049 Validation RMSE: 1.5834514110139875\n",
      "Epoch: 22 Training RMSE: 1.333890864603513 Validation RMSE: 1.56972975420752\n",
      "Epoch: 23 Training RMSE: 1.3323360047833894 Validation RMSE: 1.5688687760115523\n",
      "Epoch: 24 Training RMSE: 1.3233483634298007 Validation RMSE: 1.5674806201726443\n",
      "Epoch: 25 Training RMSE: 1.3173876003010916 Validation RMSE: 1.571191010202966\n",
      "Epoch: 26 Training RMSE: 1.3164298289489584 Validation RMSE: 1.564671551731707\n",
      "Epoch: 27 Training RMSE: 1.3153507102929816 Validation RMSE: 1.5637161415178709\n",
      "Epoch: 28 Training RMSE: 1.3095934388597659 Validation RMSE: 1.563282659197336\n",
      "Epoch: 29 Training RMSE: 1.3071697047074893 Validation RMSE: 1.5569918623055679\n",
      "Epoch: 30 Training RMSE: 1.3060985210694056 Validation RMSE: 1.5571281771347538\n",
      "Epoch: 31 Training RMSE: 1.30346863957344 Validation RMSE: 1.5539872343292145\n",
      "Epoch: 32 Training RMSE: 1.3000705370854406 Validation RMSE: 1.552732191135798\n",
      "Epoch: 33 Training RMSE: 1.2983177537234047 Validation RMSE: 1.5498202836564554\n",
      "Epoch: 34 Training RMSE: 1.2954048421675342 Validation RMSE: 1.5516726686132853\n",
      "Epoch: 35 Training RMSE: 1.2959849983995424 Validation RMSE: 1.5442418112498357\n",
      "Epoch: 36 Training RMSE: 1.2956869546567953 Validation RMSE: 1.5409062099994395\n",
      "Epoch: 37 Training RMSE: 1.2924081721501193 Validation RMSE: 1.5385807543178847\n",
      "Epoch: 38 Training RMSE: 1.29085746884906 Validation RMSE: 1.537461882144566\n",
      "Epoch: 39 Training RMSE: 1.2866412136932357 Validation RMSE: 1.5334793740602894\n",
      "Epoch: 40 Training RMSE: 1.2825459850785443 Validation RMSE: 1.5338747193184752\n",
      "Epoch: 41 Training RMSE: 1.2821049975744407 Validation RMSE: 1.5282651537841012\n",
      "Epoch: 42 Training RMSE: 1.2798648349840758 Validation RMSE: 1.5279213996356784\n",
      "Epoch: 43 Training RMSE: 1.278135884817753 Validation RMSE: 1.5280932599138053\n",
      "Epoch: 44 Training RMSE: 1.2769823092033203 Validation RMSE: 1.5254337024023243\n",
      "Epoch: 45 Training RMSE: 1.275447608719847 Validation RMSE: 1.5456563471259859\n",
      "Epoch: 46 Training RMSE: 1.2738392774942389 Validation RMSE: 1.5218938524028285\n",
      "Epoch: 47 Training RMSE: 1.2715718058959127 Validation RMSE: 1.5157987070054086\n",
      "Epoch: 48 Training RMSE: 1.2722301711567638 Validation RMSE: 1.5157425477127247\n",
      "Epoch: 49 Training RMSE: 1.2682727372024112 Validation RMSE: 1.5273491418114784\n",
      "Epoch: 50 Training RMSE: 1.2651081653352847 Validation RMSE: 1.507989728334372\n",
      "Epoch: 51 Training RMSE: 1.2639073295713628 Validation RMSE: 1.5047722741593357\n",
      "Epoch: 52 Training RMSE: 1.258463656925031 Validation RMSE: 1.517060480134428\n",
      "Epoch: 53 Training RMSE: 1.2570394607559132 Validation RMSE: 1.5040952848576625\n",
      "Epoch: 54 Training RMSE: 1.253796589586191 Validation RMSE: 1.4988875373305166\n",
      "Epoch: 55 Training RMSE: 1.258648598915367 Validation RMSE: 1.5031297892156097\n",
      "Epoch: 56 Training RMSE: 1.2535115103803676 Validation RMSE: 1.504742475601914\n",
      "Epoch: 57 Training RMSE: 1.249909052644793 Validation RMSE: 1.4946631489211426\n",
      "Epoch: 58 Training RMSE: 1.2506520919825619 Validation RMSE: 1.48636380840037\n",
      "Epoch: 59 Training RMSE: 1.2486060652078161 Validation RMSE: 1.4883696053364168\n",
      "Epoch: 60 Training RMSE: 1.2452395311786009 Validation RMSE: 1.4869746775228332\n",
      "Epoch: 61 Training RMSE: 1.2448333900118742 Validation RMSE: 1.4866969119746238\n",
      "Epoch: 62 Training RMSE: 1.24117627020111 Validation RMSE: 1.4767879422394306\n",
      "Epoch: 63 Training RMSE: 1.2417935479426516 Validation RMSE: 1.48004841687685\n",
      "Epoch: 64 Training RMSE: 1.2397499466127504 Validation RMSE: 1.4910174825809217\n",
      "Epoch: 65 Training RMSE: 1.2393112909078583 Validation RMSE: 1.4809072756121893\n",
      "Epoch: 66 Training RMSE: 1.2346933710891612 Validation RMSE: 1.4930534318792914\n",
      "Epoch: 67 Training RMSE: 1.2349810038245865 Validation RMSE: 1.4605849073891135\n",
      "Epoch: 68 Training RMSE: 1.2315386830376032 Validation RMSE: 1.465460473885454\n",
      "Epoch: 69 Training RMSE: 1.2340668664935874 Validation RMSE: 1.4573103185809582\n",
      "Epoch: 70 Training RMSE: 1.2315148393760598 Validation RMSE: 1.4536299837063669\n",
      "Epoch: 71 Training RMSE: 1.229309306107059 Validation RMSE: 1.4518662525774375\n",
      "Epoch: 72 Training RMSE: 1.2284856366805492 Validation RMSE: 1.4539870324814448\n",
      "Epoch: 73 Training RMSE: 1.226630039871082 Validation RMSE: 1.4564379330220307\n",
      "Epoch: 74 Training RMSE: 1.2206039516607088 Validation RMSE: 1.4569550708318542\n",
      "Epoch: 75 Training RMSE: 1.2243279548763872 Validation RMSE: 1.4487453952216913\n",
      "Epoch: 76 Training RMSE: 1.2215233711180096 Validation RMSE: 1.446965183187499\n",
      "Epoch: 77 Training RMSE: 1.2200249571663289 Validation RMSE: 1.456794733894995\n",
      "Epoch: 78 Training RMSE: 1.2174778664540093 Validation RMSE: 1.4446922549768242\n",
      "Epoch: 79 Training RMSE: 1.2138749119652972 Validation RMSE: 1.4397085432555388\n",
      "Epoch: 80 Training RMSE: 1.216071310431523 Validation RMSE: 1.4303731967100508\n",
      "Epoch: 81 Training RMSE: 1.211013944432742 Validation RMSE: 1.4478753338730912\n",
      "Epoch: 82 Training RMSE: 1.2094474030959563 Validation RMSE: 1.4375302890996673\n",
      "Epoch: 83 Training RMSE: 1.2101887986105264 Validation RMSE: 1.429261210745922\n",
      "Epoch: 84 Training RMSE: 1.211353543173995 Validation RMSE: 1.423722132301491\n",
      "Epoch: 85 Training RMSE: 1.2068884419253354 Validation RMSE: 1.4194887829211082\n",
      "Epoch: 86 Training RMSE: 1.2060161321810696 Validation RMSE: 1.4187854547477927\n",
      "Epoch: 87 Training RMSE: 1.203446449884486 Validation RMSE: 1.421191371686038\n",
      "Epoch: 88 Training RMSE: 1.2042993968652271 Validation RMSE: 1.4134335509602944\n",
      "Epoch: 89 Training RMSE: 1.2033228616054645 Validation RMSE: 1.411189769465197\n",
      "Epoch: 90 Training RMSE: 1.200128295810375 Validation RMSE: 1.4059495312597665\n",
      "Epoch: 91 Training RMSE: 1.200036592860069 Validation RMSE: 1.4146665346956326\n",
      "Epoch: 92 Training RMSE: 1.198848840423504 Validation RMSE: 1.406304682636719\n",
      "Epoch: 93 Training RMSE: 1.1970817983959534 Validation RMSE: 1.4160686310701267\n",
      "Epoch: 94 Training RMSE: 1.194471402361549 Validation RMSE: 1.409700694035563\n",
      "Epoch: 95 Training RMSE: 1.1905210524582441 Validation RMSE: 1.4061569811128631\n",
      "Epoch: 96 Training RMSE: 1.1949345219361873 Validation RMSE: 1.4101140784072819\n",
      "Epoch: 97 Training RMSE: 1.1910736115104774 Validation RMSE: 1.4161673249808502\n",
      "Epoch: 98 Training RMSE: 1.1889762180897725 Validation RMSE: 1.3994760261651438\n",
      "Epoch: 99 Training RMSE: 1.188418869216997 Validation RMSE: 1.4001834080934106\n",
      "Epoch: 100 Training RMSE: 1.188954779462161 Validation RMSE: 1.3960570737073983\n",
      "Epoch: 101 Training RMSE: 1.1868524714283117 Validation RMSE: 1.3968299437097305\n",
      "Epoch: 102 Training RMSE: 1.1873868294472447 Validation RMSE: 1.378283394472718\n",
      "Epoch: 103 Training RMSE: 1.184694170566753 Validation RMSE: 1.3920635622043132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104 Training RMSE: 1.18206055969973 Validation RMSE: 1.3804742699836345\n",
      "Epoch: 105 Training RMSE: 1.183280599004943 Validation RMSE: 1.3862975836174505\n",
      "Epoch: 106 Training RMSE: 1.180412348716062 Validation RMSE: 1.3862559918342896\n",
      "Epoch: 107 Training RMSE: 1.1805759828502103 Validation RMSE: 1.3950111714620612\n",
      "Epoch: 108 Training RMSE: 1.1784556667559856 Validation RMSE: 1.4398088785501477\n",
      "Epoch: 109 Training RMSE: 1.1778124660955318 Validation RMSE: 1.3659254775748524\n",
      "Epoch: 110 Training RMSE: 1.1763889148984072 Validation RMSE: 1.3791153075311016\n",
      "Epoch: 111 Training RMSE: 1.1761411757982196 Validation RMSE: 1.3752370643778464\n",
      "Epoch: 112 Training RMSE: 1.1738540837101423 Validation RMSE: 1.3802839794746147\n",
      "Epoch: 113 Training RMSE: 1.1742216982073346 Validation RMSE: 1.367688480145891\n",
      "Epoch: 114 Training RMSE: 1.1731194050103417 Validation RMSE: 1.3726157846043383\n",
      "Epoch: 115 Training RMSE: 1.1723961401552485 Validation RMSE: 1.3619060491329398\n",
      "Epoch: 116 Training RMSE: 1.1699111081411213 Validation RMSE: 1.364422735062037\n",
      "Epoch: 117 Training RMSE: 1.171062387890458 Validation RMSE: 1.36454557950345\n",
      "Epoch: 118 Training RMSE: 1.1683053066481324 Validation RMSE: 1.3615004969486455\n",
      "Epoch: 119 Training RMSE: 1.1685835716845239 Validation RMSE: 1.3580279093732157\n",
      "Epoch: 120 Training RMSE: 1.1668716285162535 Validation RMSE: 1.3613568067288082\n",
      "Epoch: 121 Training RMSE: 1.165525519000262 Validation RMSE: 1.346188873285479\n",
      "Epoch: 122 Training RMSE: 1.1644011903540403 Validation RMSE: 1.3493598724220377\n",
      "Epoch: 123 Training RMSE: 1.1645064764985327 Validation RMSE: 1.3550324624134522\n",
      "Epoch: 124 Training RMSE: 1.1640474391452849 Validation RMSE: 1.3566057578215598\n",
      "Epoch: 125 Training RMSE: 1.16253585109792 Validation RMSE: 1.3435084736928178\n",
      "Epoch: 126 Training RMSE: 1.1613475425173216 Validation RMSE: 1.343877855523875\n",
      "Epoch: 127 Training RMSE: 1.1604373432441644 Validation RMSE: 1.3465210433963661\n",
      "Epoch: 128 Training RMSE: 1.1604940321875652 Validation RMSE: 1.340353223009149\n",
      "Epoch: 129 Training RMSE: 1.156634391285523 Validation RMSE: 1.3478313522321097\n",
      "Epoch: 130 Training RMSE: 1.1555929534474458 Validation RMSE: 1.3469524969280275\n",
      "Epoch: 131 Training RMSE: 1.1549613592905352 Validation RMSE: 1.334063265750695\n",
      "Epoch: 132 Training RMSE: 1.152658987691705 Validation RMSE: 1.334294556117332\n",
      "Epoch: 133 Training RMSE: 1.1508931742355428 Validation RMSE: 1.3379437282901105\n",
      "Epoch: 134 Training RMSE: 1.151269343769884 Validation RMSE: 1.3353819403088512\n",
      "Epoch: 135 Training RMSE: 1.1525789801730513 Validation RMSE: 1.3258195451441723\n",
      "Epoch: 136 Training RMSE: 1.1520083284906977 Validation RMSE: 1.330749597618014\n",
      "Epoch: 137 Training RMSE: 1.1525597547852107 Validation RMSE: 1.359675803496442\n",
      "Epoch: 138 Training RMSE: 1.1510186383986059 Validation RMSE: 1.3356339038898668\n",
      "Epoch: 139 Training RMSE: 1.1490649824986539 Validation RMSE: 1.3369054878003455\n",
      "Epoch: 140 Training RMSE: 1.1511224336703845 Validation RMSE: 1.3191919022057932\n",
      "Epoch: 141 Training RMSE: 1.1473032975289645 Validation RMSE: 1.3307069325560292\n",
      "Epoch: 142 Training RMSE: 1.1484392036903877 Validation RMSE: 1.3315580232381996\n",
      "Epoch: 143 Training RMSE: 1.1467422673178074 Validation RMSE: 1.3298668105731088\n",
      "Epoch: 144 Training RMSE: 1.145269262319159 Validation RMSE: 1.325395493258647\n",
      "Epoch: 145 Training RMSE: 1.1409876284813223 Validation RMSE: 1.3273791130739505\n",
      "Epoch: 146 Training RMSE: 1.1423022952811062 Validation RMSE: 1.3207733479842048\n",
      "Epoch: 147 Training RMSE: 1.1404440985129418 Validation RMSE: 1.3214094706571085\n",
      "Epoch: 148 Training RMSE: 1.1414193373572918 Validation RMSE: 1.317796728830545\n",
      "Epoch: 149 Training RMSE: 1.14104150841395 Validation RMSE: 1.3264776921827717\n",
      "Epoch: 150 Training RMSE: 1.1399886030998223 Validation RMSE: 1.3083003044727382\n",
      "Epoch: 151 Training RMSE: 1.1389348654739133 Validation RMSE: 1.3165826748233818\n",
      "Epoch: 152 Training RMSE: 1.1384444983553705 Validation RMSE: 1.3069406824612642\n",
      "Epoch: 153 Training RMSE: 1.1403198442337217 Validation RMSE: 1.3073693206717434\n",
      "Epoch: 154 Training RMSE: 1.134488237578732 Validation RMSE: 1.3146808368522185\n",
      "Epoch: 155 Training RMSE: 1.13680671249791 Validation RMSE: 1.3134828748846161\n",
      "Epoch: 156 Training RMSE: 1.1360185550160031 Validation RMSE: 1.3079983040388419\n",
      "Epoch: 157 Training RMSE: 1.1345084790000055 Validation RMSE: 1.3201710435857332\n",
      "Epoch: 158 Training RMSE: 1.1339813306828548 Validation RMSE: 1.3091493921185975\n",
      "Epoch: 159 Training RMSE: 1.1335202615338904 Validation RMSE: 1.3099957280083483\n",
      "Epoch: 160 Training RMSE: 1.134345874617375 Validation RMSE: 1.306569520734471\n",
      "Epoch: 161 Training RMSE: 1.1314978579064099 Validation RMSE: 1.3141513970120249\n",
      "Epoch: 162 Training RMSE: 1.1313034617692443 Validation RMSE: 1.2966930639740202\n",
      "Epoch: 163 Training RMSE: 1.1311192702804342 Validation RMSE: 1.303547901809297\n",
      "Epoch: 164 Training RMSE: 1.131077964405097 Validation RMSE: 1.294996233436762\n",
      "Epoch: 165 Training RMSE: 1.1281201370409428 Validation RMSE: 1.3098009081567534\n",
      "Epoch: 166 Training RMSE: 1.1304763838977374 Validation RMSE: 1.3055855141138073\n",
      "Epoch: 167 Training RMSE: 1.1258335175717906 Validation RMSE: 1.3029367737284105\n",
      "Epoch: 168 Training RMSE: 1.1282830844798217 Validation RMSE: 1.3001734276145482\n",
      "Epoch: 169 Training RMSE: 1.1246872999297848 Validation RMSE: 1.2913755783589407\n",
      "Epoch: 170 Training RMSE: 1.1257052304603914 Validation RMSE: 1.304442265355428\n",
      "Epoch: 171 Training RMSE: 1.124803184922922 Validation RMSE: 1.3063687563577995\n",
      "Epoch: 172 Training RMSE: 1.1253492739824946 Validation RMSE: 1.2971616631202152\n",
      "Epoch: 173 Training RMSE: 1.1236460970166622 Validation RMSE: 1.3002453897681487\n",
      "Epoch: 174 Training RMSE: 1.1257418214883925 Validation RMSE: 1.2898891589553136\n",
      "Epoch: 175 Training RMSE: 1.1233520474883802 Validation RMSE: 1.2957138393473135\n",
      "Epoch: 176 Training RMSE: 1.1211368610106196 Validation RMSE: 1.294805291755971\n",
      "Epoch: 177 Training RMSE: 1.120307569864277 Validation RMSE: 1.2983470555910321\n",
      "Epoch: 178 Training RMSE: 1.1220395793289928 Validation RMSE: 1.2888787518332767\n",
      "Epoch: 179 Training RMSE: 1.1220778092194907 Validation RMSE: 1.3020726141877286\n",
      "Epoch: 180 Training RMSE: 1.1213980275273874 Validation RMSE: 1.3017387800792568\n",
      "Epoch: 181 Training RMSE: 1.1206948489731907 Validation RMSE: 1.2911090823712352\n",
      "Epoch: 182 Training RMSE: 1.1183443465396363 Validation RMSE: 1.2938925523274487\n",
      "Epoch: 183 Training RMSE: 1.1208706815847325 Validation RMSE: 1.2850305289610175\n",
      "Epoch: 184 Training RMSE: 1.1148588002022648 Validation RMSE: 1.2979521719942873\n",
      "Epoch: 185 Training RMSE: 1.1176020265787794 Validation RMSE: 1.280272949807858\n",
      "Epoch: 186 Training RMSE: 1.1172041068907865 Validation RMSE: 1.2996506273682258\n",
      "Epoch: 187 Training RMSE: 1.1152626799693484 Validation RMSE: 1.294213360879573\n",
      "Epoch: 188 Training RMSE: 1.1145402930066133 Validation RMSE: 1.295117296423291\n",
      "Epoch: 189 Training RMSE: 1.11387653772108 Validation RMSE: 1.2804318035542719\n",
      "Epoch: 190 Training RMSE: 1.1134366898144152 Validation RMSE: 1.2894349589925993\n",
      "Epoch: 191 Training RMSE: 1.1152834308601396 Validation RMSE: 1.3000366080582182\n",
      "Epoch: 192 Training RMSE: 1.1137088325388702 Validation RMSE: 1.2852148954731757\n",
      "Epoch: 193 Training RMSE: 1.11229408095997 Validation RMSE: 1.2750632064425051\n",
      "Epoch: 194 Training RMSE: 1.1132105147028806 Validation RMSE: 1.2915433183927896\n",
      "Epoch: 195 Training RMSE: 1.1130965077945234 Validation RMSE: 1.2845104531914642\n",
      "Epoch: 196 Training RMSE: 1.1102210437197122 Validation RMSE: 1.2809422625514095\n",
      "Epoch: 197 Training RMSE: 1.109279960431283 Validation RMSE: 1.2859173421545256\n",
      "Epoch: 198 Training RMSE: 1.1100546948759187 Validation RMSE: 1.2877816063903094\n",
      "Epoch: 199 Training RMSE: 1.1097753608471224 Validation RMSE: 1.2720307589404103\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Build and train model\n",
    "input: B x 3 x 76 x 28 features\n",
    "output: B x 76 net rates\n",
    "where 76 is the number of stations,\n",
    "B is the batch size,\n",
    "3 is 3 hours in a row,\n",
    "28 is the number of features for each station at a given hour\n",
    "\"\"\"\n",
    "N_EPOCH = 200\n",
    "BATCH_SIZE = 64\n",
    "NUM_OUTPUTS = 76\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "class DriveData(data.Dataset):\n",
    "  def __init__(self, samples, labels, transform=None):\n",
    "    self.transform = transform\n",
    "    self.__xs = samples\n",
    "    self.__ys = labels\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return (self.__xs[index], self.__ys[index])\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.__xs)\n",
    "  \n",
    "class ConvNet(nn.Module):\n",
    "  def __init__(self, num_outputs=76):\n",
    "    super(ConvNet, self).__init__()\n",
    "    self.features = nn.Sequential(\n",
    "      nn.Conv2d(3, 9, kernel_size=5, stride=1),\n",
    "      nn.BatchNorm2d(9),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Conv2d(9, 16, kernel_size=3, stride=1),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Conv2d(16, 16, kernel_size=3, stride=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    self.fc = nn.Sequential(\n",
    "      nn.Linear(112, 128),\n",
    "      nn.Sigmoid(),\n",
    "      nn.Linear(128, num_outputs))\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.features(x)\n",
    "    out = out.reshape(out.size(0), -1)\n",
    "    out = self.fc(out)\n",
    "    return out\n",
    "  \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "loss_list = []\n",
    "valid_list = []\n",
    "model = ConvNet().to(device)\n",
    "model = model.double()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n",
    "train_dataset = DriveData(samples[0: 2600], labels[0: 2600])\n",
    "valid_dataset = DriveData(samples[2600: 3285], labels[2600: 3285])\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=1, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, num_workers=1, shuffle=False)\n",
    "for epoch in range(N_EPOCH):\n",
    "  correct = 0\n",
    "  count = 0\n",
    "  loss_total = 0\n",
    "  for i, (seqs, labels) in enumerate(train_loader):\n",
    "    seqs = seqs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(seqs)\n",
    "    count += 1\n",
    "    loss = torch.sqrt(criterion(outputs, torch.autograd.Variable(labels.double())))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_total += loss.item()\n",
    "  loss_list.append(loss_total/count)\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    predictions = []\n",
    "    Y_valid = []\n",
    "    for seqs, labels in valid_loader:\n",
    "      seqs = seqs.to(device)\n",
    "      labels = labels.to(device)\n",
    "      outputs = model(seqs)\n",
    "      predictions.extend(outputs.data.numpy())\n",
    "      Y_valid.extend(labels.data.numpy())\n",
    "    valid_list.append(sqrt(mean_squared_error(Y_valid, predictions)))\n",
    "    print(\"Epoch:\", epoch, \"Training RMSE:\", loss_total/count, \"Validation RMSE:\", sqrt(mean_squared_error(Y_valid, predictions)))\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ax.plot(loss_list)\n",
    "ax.plot(valid_list)\n",
    "plt.legend(['Traning', 'Validation'], loc='upper left')\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each row are 76 net rate of 76 station. We have 3285 - 2600 = 685 rows in the validation set.\n",
      "[[ -1.  -0.   1. ...,   8.   1.   1.]\n",
      " [  1.  -0.  -0. ...,   2.   1.   1.]\n",
      " [  1.   1.  -0. ...,   1.  -0.   1.]\n",
      " ..., \n",
      " [  1.   1.   1. ...,   1.   1.   1.]\n",
      " [  5.   1.  -0. ...,  11.   3.   1.]\n",
      " [  4.  -0.  -0. ...,  21.   5.   1.]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Validate model\"\"\"\n",
    "# Validate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  predictions = []\n",
    "  Y_valid = []\n",
    "  for seqs, labels in valid_loader:\n",
    "    seqs = seqs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(seqs)\n",
    "    predictions.extend(outputs.data.numpy())\n",
    "    Y_valid.extend(labels.data.numpy())\n",
    "  \n",
    "  print(\"Each row are 76 net rate of 76 station. We have 3285 - 2600 = 685 rows in the validation set.\")\n",
    "  print(np.ceil(outputs.data.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
